{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ebb220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib as matplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dff5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#found that Apple Music Play Activity.csv is the one with the most useful and full features \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "df=pd.read_csv(rf\".\\Apple Music Play Activity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95341913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can see we have a lot of columns so we need to get rid of useless ones based on systematic rules \n",
    "nulls = df.isna().mean().sort_values(ascending=False)\n",
    "unique = df.nunique().sort_values()\n",
    "\n",
    "# Step 1 ‚Äî identify columns to drop // drop  where: null percentage is greater than or equal to 90% and where there is only no or 1 unique value\n",
    "drop_cols = nulls[(nulls >= 0.9) | (unique == 0) | (unique == 1)].index\n",
    "\n",
    "# Step 2 ‚Äî drop them\n",
    "newdf = df.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f61cc5a",
   "metadata": {},
   "source": [
    "These were columns that after I looked through decided to dispose of since they had no valuble meaning to me:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a981931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all columns that have keywords in their name\n",
    "keywords_to_drop = [\"Container Origin\",\"Container Album Name\",\"Container Name\",\"Milliseconds Since Play\",\"Event Received Timestamp\",\"Event Timestamp\",\"Event Post Date\",\"Evaluation Variant\",\"Source Type\",\"ID\", \"Client\",\"Version\",\"Device\",\"Offline\",\"IP\",\"User's\",\"Provided\",\"Siri\",\"Display\",\"Use Listening\", \"Subscription\", \"Session Is\", \"Personalized\",\"Ownership\",\"Media Type\",\"Media Bundle\",\"Item Type\",\"Vocal\",\"Event Reason Hint\",\"Repeat Play\" ]\n",
    "newdf = newdf.drop(columns=[col for col in newdf.columns if any(k in col for k in keywords_to_drop)])\n",
    "#Drop rows where Song Name is null\n",
    "newdf = newdf.dropna(subset=[\"Song Name\"])\n",
    "newdf = newdf[~((newdf['Start Position In Milliseconds'] == 0) & (newdf['End Position In Milliseconds'] == 0) | (newdf['End Position In Milliseconds'] == 0) | (newdf['End Position In Milliseconds']).isna())]\n",
    "newdf = newdf[~((newdf['Media Duration In Milliseconds']==0) | (newdf['Media Duration In Milliseconds'].isna()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5029ab25",
   "metadata": {},
   "source": [
    "Made some additional columns from other columns to increase readability and comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4079ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of null event dates rows\n",
    "newdf=newdf[~(newdf['Event End Timestamp'].isna()|newdf['Event Start Timestamp'].isna())]\n",
    "# --- Convert timestamps to datetime objects ---\n",
    "newdf['Event Start Timestamp'] = pd.to_datetime(newdf['Event Start Timestamp'], utc=True, format=\"ISO8601\")\n",
    "newdf['Event End Timestamp'] = pd.to_datetime(newdf['Event End Timestamp'], utc=True, format=\"ISO8601\")\n",
    "\n",
    "# --- Convert durations to seconds ---\n",
    "newdf['Media Duration Sec'] = newdf['Media Duration In Milliseconds'] / 1000\n",
    "newdf['Play Duration Sec'] = newdf['Play Duration Milliseconds'] / 1000\n",
    "newdf['Start Position Sec'] = newdf['Start Position In Milliseconds'] / 1000\n",
    "newdf['End Position Sec'] = newdf['End Position In Milliseconds'] / 1000\n",
    "\n",
    "# --- Calculate percent of song played ---\n",
    "newdf['Percent Played'] = newdf['Play Duration Sec'] / newdf['Media Duration Sec']\n",
    "\n",
    "# --- Extract hour of day and day of week from start timestamp ---\n",
    "newdf['Hour of Day'] = newdf['Event Start Timestamp'].dt.hour\n",
    "newdf['Day of Week'] = newdf['Event Start Timestamp'].dt.day_name()\n",
    "\n",
    "# flag skipped vs finished (e.g., <80% = skipped)\n",
    "newdf['Skipped'] = newdf['Percent Played'] < 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f58faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Dropping any columns with milliseconds since we have seconds\n",
    "newdf = newdf.drop(columns=[col for col in newdf.columns if any(k in col for k in [\"Milliseconds\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df17db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time I listen the most \n",
    "FullSongsListenedTo = newdf[newdf[\"Skipped\"]==False]\n",
    "#Day I listened to the most/least songs on average: \n",
    "print(f\"Day I typically liten to the most songs: {FullSongsListenedTo[\"Day of Week\"].value_counts().idxmax()}\")\n",
    "print(f\"Day I typically liten to the least songs: {FullSongsListenedTo[\"Day of Week\"].value_counts().idxmin()}\")\n",
    "#Hour I listened to the most/least songs on average:\n",
    "print(f\"Hour I typically liten to the most songs: {FullSongsListenedTo[\"Hour of Day\"].value_counts().idxmax()}\")\n",
    "print(f\"Hour I typically liten to the least songs: {FullSongsListenedTo[\"Hour of Day\"].value_counts().idxmin()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14925d06",
   "metadata": {},
   "source": [
    "At this point i have some decent columns I can do basic analysis on but I want a little deeper insight into song metrics: BPM, Key, Valence, Loudness, Acousticness, Instrumentalness.\n",
    "To get more detailed and (In my opinion) fun analysis\n",
    "Links I found: \n",
    "https://musicapi.com/\n",
    "https://musicfetch.io/\n",
    "https://musicbrainz.org/\n",
    "https://api.wikimedia.org/\n",
    "https://audiomack.com/data-api/\n",
    "https://github.com/cyberboysumanjay/JioSaavnAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad42d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jwt\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv, dotenv_values \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "TEAM_ID = os.getenv(\"TEAM_ID\")\n",
    "KEY_ID = os.getenv(\"KEY_ID\")\n",
    "PRIVATE_KEY_PATH = os.path.normpath(os.getenv(\"PRIVATE_KEY_PATH\"))\n",
    "\n",
    "with open(PRIVATE_KEY_PATH, \"r\") as f:\n",
    "    private_key = f.read()\n",
    "\n",
    "now = int(time.time())\n",
    "\n",
    "payload = {\n",
    "    \"iss\": TEAM_ID,           # issuer = Team ID\n",
    "    \"iat\": now,               # issued at\n",
    "    \"exp\": now + 15777000,    # max 6 months\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"alg\": \"ES256\",\n",
    "    \"kid\": KEY_ID,\n",
    "}\n",
    "\n",
    "token = jwt.encode(\n",
    "    payload,\n",
    "    private_key,\n",
    "    algorithm=\"ES256\",\n",
    "    headers=headers\n",
    ")\n",
    "\n",
    "#For every song fetch the artist and verify it with me only unique songs in my data \n",
    "#find every unique song n time efficency\n",
    "#I'll do parallel requests to speed it up as well. asyncio and aiohttp\n",
    "unique_songs = newdf[\"Song Name\"].unique()\n",
    "\n",
    "import sqlite3\n",
    "#Making a db item we can view in sqlite\n",
    "conn = sqlite3.connect(\"unique_songs.db\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS songs (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    song_name TEXT UNIQUE,\n",
    "    artist_name\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "data = [(str(x),) for x in unique_songs]\n",
    "\n",
    "cur.executemany(\"INSERT OR IGNORE INTO songs (song_name) VALUES (?)\", data)\n",
    "conn.commit()\n",
    "c = conn.cursor()\n",
    "\n",
    "# Check existing columns\n",
    "c.execute(\"PRAGMA table_info(songs)\")\n",
    "cols = [row[1] for row in c.fetchall()]\n",
    "\n",
    "if \"artist_name\" not in cols:\n",
    "    c.execute(\"ALTER TABLE songs ADD COLUMN artist_name TEXT\")\n",
    "    conn.commit()\n",
    "\n",
    "c.execute(\"SELECT song_name FROM songs WHERE artist_name IS NULL\")\n",
    "songs_to_fill = [row[0] for row in c.fetchall()]   \n",
    "from tqdm import tqdm\n",
    "total = len(songs_to_fill)\n",
    "pbar = tqdm(total=total, desc=\"Fetching artists\", unit=\"song\")\n",
    "import threading\n",
    "from queue import Queue\n",
    "from urllib.parse import quote_plus\n",
    "# --------- your existing function (KEEP IT) ----------\n",
    "def fetch_artist(song_name):\n",
    "    \n",
    "    url = f\"https://api.music.apple.com/v1/catalog/US/search?types=songs&term={quote_plus(song_name)}\"\n",
    "    try:\n",
    "        res = requests.get(url, headers={\"Authorization\": f\"Bearer {token}\"})\n",
    "        data = res.json()\n",
    "        return data[\"results\"][\"songs\"][\"data\"][0][\"attributes\"][\"artistName\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching: {song_name} -> {e}\")\n",
    "        return None\n",
    "\n",
    "# --------- threading system ----------\n",
    "\n",
    "q = Queue()\n",
    "results = Queue()\n",
    "def worker():\n",
    "    while True:\n",
    "        song = q.get()\n",
    "        if song is None: #Only activates if NONE is explicitly in the queue, otherwise it just waits for the next item\n",
    "            q.task_done()\n",
    "            break\n",
    "\n",
    "        artist = fetch_artist(song)\n",
    "        if artist:\n",
    "            results.put((song, artist))   # send to DB thread\n",
    "        q.task_done()\n",
    "\n",
    "def db_writer():\n",
    "    conn = sqlite3.connect(\"unique_songs.db\")\n",
    "    c = conn.cursor()\n",
    "\n",
    "    batch = []\n",
    "    BATCH_SIZE = 50\n",
    "\n",
    "    while True:\n",
    "        item = results.get()\n",
    "        if item is None:\n",
    "            results.task_done()\n",
    "            break\n",
    "\n",
    "        song, artist = item\n",
    "        batch.append((artist, song))\n",
    "\n",
    "        if len(batch) >= BATCH_SIZE:\n",
    "            c.executemany(\n",
    "                \"UPDATE songs SET artist_name=? WHERE song_name=?\",\n",
    "                batch\n",
    "            )\n",
    "            conn.commit()\n",
    "            pbar.update(len(batch))\n",
    "            batch.clear()\n",
    "\n",
    "        results.task_done()\n",
    "\n",
    "    # flush remaining\n",
    "    if batch:\n",
    "        c.executemany(\n",
    "            \"UPDATE songs SET artist_name=? WHERE song_name=?\",\n",
    "            batch\n",
    "        )\n",
    "        conn.commit()\n",
    "        pbar.update(len(batch))\n",
    "\n",
    "    conn.close()\n",
    "    pbar.close()\n",
    "\n",
    "# start DB writer\n",
    "db_thread = threading.Thread(target=db_writer, daemon=True)\n",
    "db_thread.start()\n",
    "\n",
    "\n",
    "# start API workers\n",
    "# number of threads (safe range: 5‚Äì10)\n",
    "num_threads = 8\n",
    "threads = []\n",
    "for _ in range(num_threads):\n",
    "    t = threading.Thread(target=worker, daemon=True)\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "    \n",
    "\n",
    "# enqueue jobs\n",
    "for song in songs_to_fill:\n",
    "    q.put(song)\n",
    "\n",
    "q.join()          # wait for API threads\n",
    "results.join()    # wait for DB writes\n",
    "\n",
    "# stop workers\n",
    "for _ in threads:\n",
    "    q.put(None)\n",
    "\n",
    "# stop db writer\n",
    "results.put(None)\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "db_thread.join()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5553a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jwt\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv, dotenv_values \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "TEAM_ID = os.getenv(\"TEAM_ID\")\n",
    "KEY_ID = os.getenv(\"KEY_ID\")\n",
    "PRIVATE_KEY_PATH = os.path.normpath(os.getenv(\"PRIVATE_KEY_PATH\"))\n",
    "\n",
    "with open(PRIVATE_KEY_PATH, \"r\") as f:\n",
    "    private_key = f.read()\n",
    "\n",
    "now = int(time.time())\n",
    "\n",
    "payload = {\n",
    "    \"iss\": TEAM_ID,           # issuer = Team ID\n",
    "    \"iat\": now,               # issued at\n",
    "    \"exp\": now + 15777000,    # max 6 months\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"alg\": \"ES256\",\n",
    "    \"kid\": KEY_ID,\n",
    "}\n",
    "\n",
    "token = jwt.encode(\n",
    "    payload,\n",
    "    private_key,\n",
    "    algorithm=\"ES256\",\n",
    "    headers=headers\n",
    ")\n",
    "song_name = \"HOTEL LOBBY (Unc & Phew)\"\n",
    "url = f\"https://api.music.apple.com/v1/catalog/US/search?types=songs&term={song_name.replace(' ', '+')}\"\n",
    "try:\n",
    "    res = requests.get(url, headers={\"Authorization\": f\"Bearer {token}\"})\n",
    "    data = res.json()\n",
    "    print(data[\"results\"][\"songs\"][\"data\"][0][\"attributes\"][\"artistName\"])\n",
    "except:\n",
    "    print(song_name)\n",
    "    print(f\"error with response: {res.status_code }\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1170f4",
   "metadata": {},
   "source": [
    "# What type of listener am I?\n",
    "---\n",
    "## In order to kow that we need to know: \n",
    "- Time I listen the most\n",
    "  - Morning listener\n",
    "  - Late-night listener\n",
    "  - Workday listener\n",
    "  - Commute listener\n",
    "  - Day-of-week patterns\n",
    "  - Weekday vs weekend listening\n",
    "- BPM I listen to the most or at certain times \n",
    "- Key/Mode I listen to the most or at certain times\n",
    "- Energy ‚Üí intensity preference\n",
    "- Valence ‚Üí happy vs sad music\n",
    "- Loudness ‚Üí aggressive vs soft music\n",
    "- Acousticness ‚Üí organic vs digital\n",
    "- Instrumentalness ‚Üí vocal vs instrumental\n",
    "- Session length\n",
    "- Short sessions vs long sessions\n",
    "- Frequency\n",
    "- Daily listener vs occasional binge listener\n",
    "---\n",
    "\n",
    "# üéß Engagement Features\n",
    "- Interaction style\n",
    "- Average listening %\n",
    "- Skip rate\n",
    "- Replay rate\n",
    "- Completion rate\n",
    "- Repeat frequency\n",
    "- Song loyalty score\n",
    "- Artist loyalty\n",
    "- Playlist reuse\n",
    "- New music vs repeat music ratio\n",
    "# üìö Discovery Behavior\n",
    "- Exploration style\n",
    "- New artist adoption rate\n",
    "- Genre diversity\n",
    "- Exploration score\n",
    "- Algorithm dependence\n",
    "- Playlist-based vs album-based listening\n",
    "- Trend adoption speed\n",
    "# üß† Cognitive / Emotional Indicators\n",
    "- Inferred traits\n",
    "- Mood regulation (sad ‚Üí happy transitions)\n",
    "- Energy regulation\n",
    "- Stress listening\n",
    "- Focus listening\n",
    "- Motivation listening\n",
    "- Nostalgia bias\n",
    "- Comfort music behavior\n",
    "# üìä Structural Features (data science features)\n",
    "- Distribution metrics\n",
    "- Genre entropy (diversity)\n",
    "- Artist entropy\n",
    "- Temporal entropy\n",
    "- Listening consistency\n",
    "- Time clustering\n",
    "- Behavior variance\n",
    "- Habit strength\n",
    "- Pattern stability\n",
    "# üßç Listener Archetypes (what this builds into)\n",
    "- You can classify people like:\n",
    "- Example personas:\n",
    "- Routine Listener\n",
    "- Explorer\n",
    "- Comfort Listener\n",
    "- Trend Follower\n",
    "- Mood Regulator\n",
    "- Background Listener\n",
    "- Deep Listener\n",
    "- Skipper\n",
    "- Album Purist\n",
    "- Playlist Hopper\n",
    "- Night Owl Listener\n",
    "- High-Energy Listener\n",
    "- Low-Tempo Listener\n",
    "- Genre Loyalist\n",
    "- Artist Loyalist\n",
    "# üî• Real feature groups (for modeling)\n",
    "- 1) Rhythm profile\n",
    "- avg BPM\n",
    "- BPM variance\n",
    "- tempo buckets\n",
    "- 2) Energy profile\n",
    "- avg energy\n",
    "- peak energy times\n",
    "- energy transitions\n",
    "- 3) Time profile\n",
    "- hourly listening distribution\n",
    "- weekday/weekend ratio\n",
    "- 4) Loyalty profile\n",
    "- top artist share %\n",
    "- repeat song %\n",
    "- 5) Exploration profile\n",
    "- new songs/week\n",
    "- new artists/month\n",
    "- 6) Engagement profile\n",
    "- avg listen %\n",
    "- skip %"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
